{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef13791",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temporal_templates_static_2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 237\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# pred_dir = 'Test Dataset'\u001b[39;00m\n\u001b[1;32m    236\u001b[0m background \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackgrounds\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemporal_templates_static_2.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    238\u001b[0m     temporal_template_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(temporal_template_dict)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temporal_templates_static_2.txt'"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import os\n",
    "from scipy import spatial\n",
    "\n",
    "bg_mapping = {'daria' : 'bg_015.avi' , 'denis' : 'bg_026.avi' , 'eli' : 'bg_062.avi' , 'ido' : 'bg_062.avi' , 'ira' : 'bg_007.avi' , 'lena' : 'bg_026.avi' , 'lyova' : 'bg_046.avi' , 'moshe' : 'bg_070.avi' , 'shahar' : 'bg_079.avi'}\n",
    "# Frame grabber\n",
    "def frame_grabber(file):\n",
    "    # video_file = file + '.avi'\n",
    "    frames = []\n",
    "    # Opens the Video file\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    i = 0\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    frames = np.asarray(frames)\n",
    "\n",
    "    return frames\n",
    "# Read File\n",
    "def read_files(file):\n",
    "    # Reading the images from the directory\n",
    "    filename = glob.glob(file + '*png')\n",
    "    file_name = {}\n",
    "    for i in range(len(filename)):\n",
    "        file_name[i] = np.double(Image.open(str(filename[i])).convert('L'))\n",
    "    return (file_name)\n",
    "\n",
    "# Background Substraction I\n",
    "def background_subtraction(Im, background, threshold):\n",
    "    bgs = {}\n",
    "    plt.show()\n",
    "    for i in range(len(Im)):\n",
    "        bgs[i] = (np.abs(Im[i] - background) > threshold).astype(int)\n",
    "    plt.show()\n",
    "    return (bgs)\n",
    "\n",
    "# Calculate MHI\n",
    "def MHI(image, delta):\n",
    "    mhi = np.zeros((np.shape(image[0])[0], np.shape(image[0])[1]), np.uint8)\n",
    "\n",
    "    row, column = np.shape(image[0])\n",
    "\n",
    "    for timestamp in range(0, len(image)):\n",
    "        frame = image[timestamp]\n",
    "\n",
    "        for y in range(row):\n",
    "            for x in range(column):\n",
    "                if (frame[y, x] == 1):\n",
    "                    mhi[y, x] = timestamp + 1\n",
    "                else:\n",
    "                    if (mhi[y, x] < timestamp - delta):\n",
    "                        mhi[y, x] = 0\n",
    "\n",
    "    # fig = plt.figure(figsize=(5, 5))\n",
    "    # fig.suptitle('The final MHI is', fontsize=20)\n",
    "    # plt.imshow(mhi)\n",
    "    # plt.gray()\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return mhi\n",
    "\n",
    "# Calculate MEI\n",
    "def MEI(Im):\n",
    "    mei = np.zeros((np.shape(Im[0])[0], np.shape(Im[0])[1]), np.uint8)\n",
    "\n",
    "    # The MEI/MHI duration should include all image diff results in the sequence into the final template.\n",
    "    # So, frames to be considered i.e., delta = 22\n",
    "\n",
    "    for i in range(len(Im)):\n",
    "        mei = mei + Im[i]\n",
    "\n",
    "        mei = mei > 0\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.suptitle('The final MEI is', fontsize=20)\n",
    "    plt.imshow(mei)\n",
    "    plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return (np.asarray(mei))\n",
    "\n",
    "# Calculate MEI as threshold of MHI\n",
    "def MEI_Thresh(mhi):\n",
    "    mei = mhi > 0\n",
    "    return mei\n",
    "\n",
    "# Normalize MHI\n",
    "def normalize(mhi):\n",
    "    mhi_n = np.maximum(0, np.divide((mhi - (np.min(mhi[np.nonzero(mhi)]) - 1.0)),\n",
    "                                    (np.max(mhi[np.nonzero(mhi)]) - (np.min(mhi[np.nonzero(mhi)]) - 1.0))))\n",
    "\n",
    "    print('Maximum value in MHI: ', np.max(mhi_n))\n",
    "    print('Minimum value in MHI: ', np.min(mhi_n))\n",
    "\n",
    "    return (mhi_n)\n",
    "\n",
    "# Calculate similitude moments\n",
    "def similitude_moments(Im):\n",
    "    y, x = np.mgrid[range(Im.shape[0]), range(Im.shape[1])]\n",
    "\n",
    "    similitude_moments = []\n",
    "\n",
    "    x_bar = np.sum(x * Im) / np.sum(Im)\n",
    "    y_bar = np.sum(y * Im) / np.sum(Im)\n",
    "\n",
    "    # Since 2 <= (i+j) <=3, the similitude moments\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if (2 <= (i + j) <= 3):\n",
    "                s = np.sum(((x - x_bar) ** i) * ((y - y_bar) ** j) * Im) / (np.sum(Im)) ** (((i + j) / 2) + 1)\n",
    "                similitude_moments.append(s)\n",
    "\n",
    "    return (similitude_moments)\n",
    "\n",
    "def get_temporal_template(file_name , bg_file_name):\n",
    "    # Threshold for Background Substraction\n",
    "    thresh = 40\n",
    "    # Delta value for the number of frames to keep\n",
    "    delta = 30\n",
    "    # Grab frames from video of action\n",
    "    imgFrameData = frame_grabber(file_name)\n",
    "    imgGrayscaleFrameData = {}\n",
    "    for i,image in enumerate(imgFrameData):\n",
    "        grayscale = rgb2gray(image)\n",
    "        # Convert color image to grayscale image\n",
    "        imgGrayscaleFrameData[i] = (grayscale * 255).astype(int)\n",
    "    # Get image of background\n",
    "    bgFrameData = frame_grabber(bg_file_name)\n",
    "    # Convert background image from color to grayscale\n",
    "    bgImage = (rgb2gray(bgFrameData[0]) * 255).astype(int)\n",
    "    # Perform background substraction on the images captured from the videos\n",
    "    bgSubsImages = background_subtraction(imgGrayscaleFrameData , bgImage, threshold=thresh)\n",
    "    # Get the MHI from the background subtracted images\n",
    "    mhiImg = MHI(bgSubsImages , delta)\n",
    "    # Normal MHI Image\n",
    "    normMhiImg = normalize(mhiImg)\n",
    "    # plt.imshow(normMhiImg , cmap='gray')\n",
    "    # Get MEI\n",
    "    meiImg = MEI_Thresh(normMhiImg)\n",
    "    # plt.imshow(meiImg , cmap='gray')\n",
    "    # plt.show()\n",
    "    # Get Similitude moments of MHI and MEI\n",
    "    mhiSimilitude = similitude_moments(normMhiImg)\n",
    "    meiSimilitude = similitude_moments(meiImg)\n",
    "    result = []\n",
    "    result.extend(mhiSimilitude)\n",
    "    result.extend(meiSimilitude)\n",
    "    return result\n",
    "\n",
    "def create_temporal_template_dict():\n",
    "    tt_dict = {}\n",
    "    rootdir = 'Static Train'\n",
    "    # rootdir = 'Train Dataset'\n",
    "    background = 'Backgrounds'\n",
    "    for subdir, dir, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            act_name = file.split('.')[0].split('_')[0]\n",
    "            print(act_name)\n",
    "            bg_path = background + '/' + bg_mapping[act_name]\n",
    "            filePath = rootdir + '/' + file\n",
    "            temporal_template = get_temporal_template(filePath, bg_path)\n",
    "            tt_dict[file] = temporal_template\n",
    "            print(file + \" processed.\")\n",
    "            print(temporal_template)\n",
    "    print(tt_dict)\n",
    "    with open('temporal_templates_static_3.txt', 'w') as f:\n",
    "        f.write(json.dumps(tt_dict))\n",
    "\n",
    "def get_euclidean_dist(test_template , train_template):\n",
    "    return spatial.distance.euclidean(test_template , train_template)\n",
    "\n",
    "def get_mahalanobis_dist(test_template , train_template):\n",
    "    # Method - 1 (Using mahalanobis library)\n",
    "    # a = np.asarray(test_template)\n",
    "    # b = np.asarray(train_template)\n",
    "    # K = np.cov((a , b) , rowvar=False)\n",
    "    # k_inv = np.linalg.inv(K)\n",
    "    # return spatial.distance.mahalanobis(test_template , train_template , k_inv)\n",
    "    # Method - 2 (Using formula in slides)\n",
    "    test_template = np.asarray(test_template)\n",
    "    train_template = np.asarray(train_template)\n",
    "    t = np.vstack((test_template, train_template))\n",
    "    # print(type(t))\n",
    "    k = np.cov(t.T)\n",
    "    # print(k.shape)\n",
    "    mean_temp = np.mean(t , axis=0)\n",
    "    # print(mean.shape)\n",
    "    md = np.matmul(np.matmul((test_template - mean_temp).T, (np.linalg.pinv(k))), (test_template - mean_temp))\n",
    "    return (md)\n",
    "    # return md\n",
    "\n",
    "def get_mahalanobis_dist_pinv(test_template , train_template):\n",
    "    t = np.array([train_template, test_template]).T\n",
    "    k = np.cov(t)\n",
    "    md = spatial.distance.mahalanobis(train_template, test_template, np.linalg.pinv(k))\n",
    "    return (md)\n",
    "\n",
    "def get_cosine_dist(test_template , train_template):\n",
    "    return spatial.distance.cosine(test_template , train_template)\n",
    "\n",
    "def predict_activity(file , background , temporal_template_dict):\n",
    "    pred_temporal_template = get_temporal_template(file, background)\n",
    "    min_dist = float(\"inf\")\n",
    "    activity = \"\"\n",
    "    for k , v in temporal_template_dict.items():\n",
    "        # Using mahalanobis distance\n",
    "        dist = get_mahalanobis_dist(pred_temporal_template , v)\n",
    "        # Using euclidean distance\n",
    "        # dist = get_euclidean_dist(pred_temporal_template , v)\n",
    "        # Using cosine distance\n",
    "        # dist = get_cosine_dist(pred_temporal_template , v)\n",
    "        if(dist < min_dist):\n",
    "            min_dist = dist\n",
    "            activity = k\n",
    "    print(min_dist)\n",
    "    return activity\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run below command to train dataset\n",
    "    # create_temporal_template_dict()\n",
    "    # Prediction Calculation\n",
    "    pred_dir = 'Static Test'\n",
    "    # pred_dir = 'Test Dataset'\n",
    "    background = 'Backgrounds'\n",
    "    with open('temporal_templates_static_2.txt' , 'r') as f:\n",
    "        temporal_template_dict = json.loads(f.read())\n",
    "    print(temporal_template_dict)\n",
    "    acc_count = 0\n",
    "    total = 0\n",
    "    for subdir, dir, files in os.walk(pred_dir):\n",
    "        for file in files:\n",
    "            pred_file_path = pred_dir + '/' + file\n",
    "            print(file)\n",
    "            act_activity = file.split('.')[0].split('_')[1]\n",
    "            act_name = file.split('.')[0].split('_')[0]\n",
    "            print(act_activity)\n",
    "            bg_path = background + '/' + bg_mapping[act_name]\n",
    "            print(bg_path)\n",
    "            result_activity = predict_activity(pred_file_path , bg_path , temporal_template_dict)\n",
    "            print(result_activity)\n",
    "            pred_activity = result_activity.split('.')[0].split('_')[1]\n",
    "            print(pred_activity)\n",
    "            print(\"------------\")\n",
    "            if(act_activity == pred_activity):\n",
    "                acc_count += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy : \",acc_count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5356b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage import color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e44d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def frame_grabber(file):\n",
    "    video_file = file + '.avi'\n",
    "    # Opens the Video file\n",
    "    cap= cv2.VideoCapture(video_file)\n",
    "    i=0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if (i < 10):\n",
    "            cv2.imwrite(file + '-00'  + str(i)+'.png',frame)\n",
    "        elif (10 <= i < 100) :\n",
    "            cv2.imwrite(file + '-0' + str(i) + '.png', frame)\n",
    "        else:\n",
    "            cv2.imwrite(file + '-' + str(i) + '.png', frame)\n",
    "        i+=1\n",
    " \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863ccd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(file):\n",
    "    #Reading the images from the directory\n",
    "    filename = glob.glob(file + '*png')\n",
    "\n",
    "    file_name = {}\n",
    "\n",
    "    for i in range(len(filename)):\n",
    "        file_name[i] = np.double(Image.open(str(filename[i])).convert('L'))\n",
    "        \n",
    "    return(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9b7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Function for image differencing by using closing and dilate to remove or cleanup tiny regions\n",
    "\n",
    "def image_differencing(Im,threshold):\n",
    "    diffIm = []\n",
    "\n",
    "    for i in range(len(Im)-1):\n",
    "        m = abs(np.subtract(Im[i+1],Im[i])) >= threshold\n",
    "        m = np.uint8(m*1)\n",
    "    \n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "        n = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel)\n",
    "        cleaned = cv2.dilate(n, kernel, iterations = 1)\n",
    "    \n",
    "        diffIm.append(cleaned)\n",
    "        \n",
    "    return(diffIm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405ae681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_subtraction(Im, background, threshold):\n",
    "    bgs = {}\n",
    "    for i in range(len(Im)):\n",
    "        bgs[i] = abs(Im[i] - background) > threshold\n",
    "        \n",
    "    return(bgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da67c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MHI(image, delta):\n",
    "    mhi = np.zeros((np.shape(image[0])[0],np.shape(image[0])[1]), np.uint8)\n",
    "    \n",
    "    row, column = np.shape(image[0])\n",
    "    \n",
    "    for timestamp in range(0,len(image)):\n",
    "        frame = image[timestamp]\n",
    "\n",
    "        for y in range(row):\n",
    "            for x in range(column):\n",
    "                if(frame[y,x] == 1):\n",
    "                    mhi[y,x] = timestamp\n",
    "                else:\n",
    "                    if(mhi[y,x] < timestamp - delta):\n",
    "                        mhi[y,x] = 0\n",
    "                        \n",
    "\n",
    "    fig= plt.figure(figsize=(5,5))\n",
    "    fig.suptitle('The final MHI is', fontsize = 20)\n",
    "    plt.imshow(mhi)\n",
    "    plt.gray()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return(np.asarray(mhi))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d158f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Function for calculating Binary Motion Energy Image\n",
    "def MEI(Im):\n",
    "    mei = np.zeros((np.shape(Im[0])[0],np.shape(Im[0])[1]), np.uint8)\n",
    "    \n",
    "    #The MEI/MHI duration should include all image diff results in the sequence into the final template.\n",
    "    #So, frames to be considered i.e., delta = 22\n",
    "    \n",
    "    for i in range(len(Im)):\n",
    "        mei = mei + Im[i]\n",
    "    \n",
    "        mei = mei>0\n",
    "        \n",
    "    fig= plt.figure(figsize=(5,5))\n",
    "    fig.suptitle('The final MEI is', fontsize = 20)  \n",
    "    plt.imshow(mei)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return(np.asarray(mei))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3775a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MEI_t(mhi):\n",
    "    mei = (mhi > 0)*1\n",
    "    fig= plt.figure(figsize=(5,5))\n",
    "    fig.suptitle('The final MEI is', fontsize = 20)\n",
    "    plt.imshow(mei)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return(np.asarray(mei))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40af32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize(mhi,mei):\n",
    "    #Normalize MHI and MEI,\n",
    "\n",
    "    mhi_n = np.maximum(0, np.divide((mhi - (np.min(mhi[np.nonzero(mhi)]) - 1.0)),(np.max(mhi[np.nonzero(mhi)]) - (np.min(mhi[np.nonzero(mhi)]) - 1.0))))\n",
    "\n",
    "    print('Maximum value in MHI: ', np.max(mhi_n))\n",
    "    print('Minimum value in MHI: ', np.min(mhi_n))\n",
    "\n",
    "    mei_n = mei*1.0\n",
    "\n",
    "    print('Maximum value in MEI: ', np.max(mei_n))\n",
    "    print('Minimum value in MEI: ', np.min(mei_n))\n",
    "    \n",
    "    return(mhi_n,mei_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b202467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Function for calculating similitude moments\n",
    "def similitude_moments(Im):\n",
    "    \n",
    "    y, x = np.mgrid[range(Im.shape[0]),range(Im.shape[1])]\n",
    "    \n",
    "    similitude_moments = []\n",
    "    \n",
    "    x_bar = np.sum(x*Im)/np.sum(Im)\n",
    "    y_bar = np.sum(y*Im)/np.sum(Im)\n",
    "    \n",
    "    #Since 2 <= (i+j) <=3, the similitude moments\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if(2 <= (i+j) <= 3):\n",
    "                s = np.sum(((x-x_bar)**i)*((y-y_bar)**j)*Im) / (np.sum(Im))**(((i+j)/2)+1)\n",
    "                similitude_moments.append(s)\n",
    "\n",
    "    return(similitude_moments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66818837",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m frame_grabber(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbg_015\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m daria_bg \u001b[38;5;241m=\u001b[39m read_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbg_015\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m daria_walk_bs \u001b[38;5;241m=\u001b[39m background_subtraction(daria_walk,\u001b[43mdaria_bg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      6\u001b[0m daria_walk_mhi \u001b[38;5;241m=\u001b[39m MHI(daria_walk_bs,\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      7\u001b[0m daria_walk_mei \u001b[38;5;241m=\u001b[39m MEI_t(daria_walk_mhi)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "frame_grabber('16_10_24_head_kick2')\n",
    "daria_walk = read_files('16_10_24_head_kick2')\n",
    "frame_grabber('bg_015')\n",
    "daria_bg = read_files('bg_015')\n",
    "daria_walk_bs = background_subtraction(daria_walk,daria_bg[0],40)\n",
    "daria_walk_mhi = MHI(daria_walk_bs,20)\n",
    "daria_walk_mei = MEI_t(daria_walk_mhi)\n",
    "\n",
    "daria_walk_mhi_n, daria_walk_mei_n = normalize(daria_walk_mhi, daria_walk_mei)\n",
    "daria_walk_mhi_sm = similitude_moments(daria_walk_mhi_n)\n",
    "daria_walk_mei_sm = similitude_moments(daria_walk_mei_n)\n",
    "print('Similitude moments for normalized MHI is:\\n', daria_walk_mhi_sm)\n",
    "print('Similitude moments for normalized MEI is:\\n', daria_walk_mei_sm)\n",
    "daria_walk_sm = daria_walk_mhi_sm + daria_walk_mei_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_grabber('/home/muhlabws4/Videolar/16_10_24_head_kick2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7af759",
   "metadata": {},
   "outputs": [],
   "source": [
    "kick = read_files('/home/muhlabws4/Videolar/16_10_24_head_kick2')\n",
    "frame_grabber('bg_015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c9b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_bg = read_files('bg_015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c92ac0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kick_bs \u001b[38;5;241m=\u001b[39m background_subtraction(kick,\u001b[43mkick_bg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      2\u001b[0m kick_mhi \u001b[38;5;241m=\u001b[39m MHI(kick_bs,\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m kick_mei \u001b[38;5;241m=\u001b[39m MEI_t(kick_mhi)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "kick_bs = background_subtraction(kick,kick_bg[0],40)\n",
    "kick_mhi = MHI(kick_bs,20)\n",
    "kick_mei = MEI_t(kick_mhi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
